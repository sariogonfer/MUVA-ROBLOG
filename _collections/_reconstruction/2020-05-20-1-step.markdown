---
layout: post
title:  "3D reconstruction."
date:   2020-05-20 00:00:00 +0100
image: /MUVA-ROBLOG/assets/images/3d-reconstruction/main.png
rating: 5
---

First, it is necesary to modify the file *3d_reconstruction.py*. This modification allows us to configure some of the variables used by the application. Theese variables are:

* The number of samples used to draw the 3D scene.
* The scalation applied to the original images.
* The size of the block used to do the patches.

```python
n_sample = None
scale = 1
block = 15
if len(sys.argv) >= 3:
n_sample = int(sys.argv[2])
if len(sys.argv) >= 4:
scale = int(sys.argv[3])
if len(sys.argv) >= 5:
block = int(sys.argv[4])

algorithm=MyAlgorithm(cameraL, cameraR, publishPoint, n_sample, scale, block)
```

Also, the *__init__* method of the **MyAlgorithm** class must be modified.

```python
def __init__(self, cameraL, cameraR, point, n_sample=None, scale=1, block=15):

	...

	self.N_SAMPLE = n_sample
	self.SCALE = scale
	self.BLOCK = block
```

Next, the code that processes the images and calculates the points of the 3D scenes. To do this, it is necessary to modify the *__init__* method to calculate the *Proyection Matrix* of the cameras and *Fundamental Matrix* of the system.



```python
def skew(x):
    return np.array([[0, -x[2], x[1]],
                     [x[2], 0, -x[0]],
                     [-x[1], x[0], 0]])

def projmat_2_fmat(P1, P2):
    p1 = np.linalg.inv(P1[:3, :3])
    p2 = np.linalg.inv(P2[:3, :3])
    p1_t = P1[:, 3]
    p2_t = P2[:, 3]
    e = skew(np.dot(p2, p2_t) - np.dot(p1, p1_t))
    return np.dot(np.dot(p2.T, e), p1)

def epi_range_from_image(epi_line, block, img):
    z = np.zeros((block * 2, img.shape[1], img.shape[2]))
    for i in np.arange(img.shape[1]):
        y = int((epi_line[1] * i + epi_line[2]) / -epi_line[0])
        z[:, i, :] = img[y-block:y+block, i]
        
    return z.astype(np.uint8)


class MyAlgorithm:
    def __init__(self, cameraL, cameraR, point, n_sample=None, scale=1, block=15):

	...
        K = np.append(self.camLeftP.K, np.zeros([3, 1]), axis=1)
        self.Pr = np.dot(K, np.array(self.camRightP.RT).reshape(4, 4)).astype(np.float)
        self.Pl = np.dot(K, np.array(self.camLeftP.RT).reshape(4, 4)).astype(np.float)
        self.F = projmat_2_fmat(self.Pl, self.Pr)
        ...

    def epiline4point(self, point, cam):
        return cv2.computeCorrespondEpilines(np.array((point)).reshape(-1, 1, 2), cam, self.F)[0][0]

          
    def algorithm(self):
        #GETTING THE IMAGES
        start_time = time.time()
        print('Procesing images...')
        def process_img(i):
            aux = cv2.cvtColor(i, cv2.COLOR_BGR2HSV)
            aux = cv2.Canny(aux, 200, 200)
            kernel = np.ones((5, 5),np.uint8)
            aux = cv2.dilate(aux,kernel,iterations = 1)
            return aux
        
        imgL_raw = self.getImage('left')
        h, w, _ = np.array(imgL_raw.shape) / self.SCALE
        imgL_raw = cv2.resize(imgL_raw, (w, h))
        imgR_raw = self.getImage('right')
        imgR_raw = cv2.resize(imgR_raw, (w, h))
        
        mask = process_img(imgL_raw)
        
        p_l = [[], []]
        p_r = [[], []]
        color = []        
        l = list(zip(*np.where(mask == 255)))
        
        print('Original sample: {}.'.format(len(l)))
        print('Reduced sample: {}.'.format(self.N_SAMPLE or len(l)))
        
        l = random.sample(l, self.N_SAMPLE or len(l))
        d = defaultdict(list)
        for y, x in l:
            d[y].append(x)
        for y, x_list in d.items():
            if y < self.BLOCK or y > (h - self.BLOCK):
                continue
            for x in x_list:
                if x < self.BLOCK or x > (w - self.BLOCK):
                    continue
                t = imgL_raw[y - self.BLOCK:y + self.BLOCK, x - self.BLOCK:x + self.BLOCK]
                epi_line = self.epiline4point((y, x), 2)
                aux = epi_range_from_image(epi_line, self.BLOCK, imgR_raw)
                p_l[0].append(h - y)
                p_l[1].append(x)
                p_r[0].append(h - y)
                x_r = np.argmax(cv2.matchTemplate(aux, t, cv2.TM_CCOEFF))
                p_r[1].append(x_r)
                color.append(imgL_raw[y, min(x+1, w - 1)])
        X = cv2.triangulatePoints(self.Pl, self.Pr, np.array(p_l).astype(np.float), np.array(p_r).astype(np.float))
        
        print('Image processed in {} seconds'.format(time.time() - start_time))
        print('Painting image.')
        start_time = time.time()
        
        for x, c in zip(zip(*X / X[3]), color):
            x = (np.array(x) / [300., 300.][self.SCALE - 1])
            x[0] = x[0] + [-15, -25][self.SCALE - 1]
            x[1] = x[1] + [5, 0][self.SCALE - 1]
            x[2] = x[2] + [-5, 0][self.SCALE - 1]
            self.point.plotPoint(list(x[:3]), list(c / 255.))
            
        print('Image painted in {} seconds'.format(time.time() - start_time))
```

<iframe width="560" height="315" src="https://www.youtube.com/embed/TpPe20nCK9Y" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

